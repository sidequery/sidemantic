---
title: "Coverage Analyzer"
---

Analyzes existing SQL queries to:
1. Generate semantic layer model definitions
2. Rewrite queries to use semantic layer syntax
3. Measure coverage gaps

## Quick Start

```python
from sidemantic import SemanticLayer
from sidemantic.core.coverage_analyzer import CoverageAnalyzer

layer = SemanticLayer(auto_register=False)
analyzer = CoverageAnalyzer(layer)

queries = ["""
    SELECT status, region, SUM(amount), COUNT(*)
    FROM orders
    WHERE status = 'completed'
    GROUP BY status, region
"""]

report = analyzer.analyze_queries(queries)
analyzer.print_report(report, verbose=True)
```

## Generate Models from Queries

```python
# Generate model definitions
models = analyzer.generate_models(report)

# Write YAML files
analyzer.write_model_files(models, output_dir="models/")
```

Generated `models/orders.yml`:
```yaml
model:
  name: orders
  table: orders
dimensions:
  - name: status
    sql: status
    type: categorical
  - name: region
    sql: region
    type: categorical
metrics:
  - name: sum_amount
    agg: sum
    sql: amount
  - name: count
    agg: count
    sql: "*"
```

## Rewrite Queries

```python
# Generate semantic layer queries
rewritten = analyzer.generate_rewritten_queries(report)
analyzer.write_rewritten_queries(rewritten, output_dir="queries/")
```

```sql
-- Original
SELECT status, region, SUM(amount), COUNT(*)
FROM orders
WHERE status = 'completed'
GROUP BY status, region

-- Rewritten
SELECT orders.status, orders.region, orders.sum_amount, orders.count
FROM orders
WHERE status = 'completed'
```

## Supported Patterns

### Basic Aggregations

Extracts dimensions from GROUP BY and metrics from aggregations:

```sql
SELECT
    status,
    SUM(amount) as revenue,
    COUNT(DISTINCT customer_id) as customers
FROM orders
GROUP BY status
```

### Complex Expressions

Handles CASE, COALESCE, CAST, math, string functions:

```sql
SELECT
    UPPER(status) as status,
    SUM(CASE WHEN priority = 'high' THEN amount ELSE 0 END) as high_priority_revenue,
    SUM(quantity * price) as total_revenue
FROM orders
GROUP BY UPPER(status)
```

Extracts underlying columns (`status`, `amount`, `quantity`, `price`).

### Time Dimensions

```sql
SELECT
    DATE_TRUNC('month', order_date) as month,
    EXTRACT(YEAR FROM order_date) as year,
    SUM(amount) as revenue
FROM orders
GROUP BY DATE_TRUNC('month', order_date), EXTRACT(YEAR FROM order_date)
```

Extracts `order_date` as time dimension. Rewrites to `orders.order_date__month`, `orders.order_date__year`.

### Derived Metrics

```sql
SELECT
    status,
    SUM(revenue) / COUNT(*) as avg_revenue_per_order,
    SUM(amount - discount) as net_amount
FROM orders
GROUP BY status
```

Extracts base metrics and derived metrics separately:
```yaml
metrics:
  - name: sum_revenue
    agg: sum
    sql: revenue
  - name: count
    agg: count
    sql: "*"
  - name: avg_revenue_per_order
    type: derived
    sql: "SUM(revenue) / COUNT(*)"
```

### Joins and Relationships

```sql
SELECT
    c.region,
    COUNT(o.order_id) as order_count
FROM customers c
JOIN orders o ON c.id = o.customer_id
GROUP BY c.region
```

Extracts relationship: `orders.customer_id` → `customers.id` (many_to_one).

```yaml
# orders.yml
relationships:
  - name: customers
    type: many_to_one
    foreign_key: customer_id
```

### Subqueries

Resolves subquery aliases to underlying tables:

```sql
SELECT
    sub.status,
    COUNT(*) as order_count
FROM (
    SELECT status, amount
    FROM orders
    WHERE amount > 100
) sub
GROUP BY sub.status
```

Extracts `orders` table and resolves `sub.status` → `orders.status`.

### Window Functions and Cumulative Metrics

Detects window functions and generates cumulative metric definitions.

**Running totals**:
```sql
SELECT
    order_date,
    SUM(amount) OVER (ORDER BY order_date) as running_total
FROM orders
```
```yaml
metrics:
  - name: running_total
    type: cumulative
    sql: "orders.sum_amount"
```

**Rolling windows**:
```sql
SELECT
    order_date,
    SUM(amount) OVER (
        ORDER BY order_date
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    ) as rolling_7day
FROM orders
```
```yaml
metrics:
  - name: rolling_7day
    type: cumulative
    sql: "orders.sum_amount"
    window: "6 days"
```

**Period-to-date**:
```sql
SELECT
    order_date,
    SUM(amount) OVER (
        PARTITION BY DATE_TRUNC('month', order_date)
        ORDER BY order_date
    ) as mtd_revenue
FROM orders
```
```yaml
metrics:
  - name: mtd_revenue
    type: cumulative
    sql: "orders.sum_amount"
    grain_to_date: "month"
```

**What's extracted**:
- Aggregation window functions: `SUM/AVG/COUNT/MIN/MAX` with `OVER()`
- Rolling windows with `ROWS BETWEEN`
- Period-to-date with `PARTITION BY DATE_TRUNC()`

**What's ignored**:
- Window-only functions: `ROW_NUMBER()`, `RANK()`, `LAG()`, `LEAD()`
- Complex window calculations with operators

For complex calculations, base aggregations are still extracted - define derived metrics on top.

### Other Patterns

- **CTEs**: Extracts from underlying tables, preserves structure in rewrites
- **GROUP BY ordinals**: `GROUP BY 1, 2` resolved to columns
- **Implicit joins**: `FROM a, b WHERE a.id = b.fk` extracts relationships
- **Self-joins**: Generates single model

## CLI Usage

```bash
# Analyze folder
sidemantic coverage-analyzer analyze queries/ --output-dir models/

# Analyze specific query
sidemantic coverage-analyzer analyze-query \
    "SELECT status, COUNT(*) FROM orders GROUP BY status"

# Generate report
sidemantic coverage-analyzer report queries/ > coverage-report.txt
```

Options:
- `--pattern "*.sql"` - File pattern
- `--output-dir` - Where to write models
- `--rewrite` - Also generate rewritten queries
- `--verbose` - Show details

## Python API

### Coverage Metrics

```python
report = analyzer.analyze_queries(queries)

print(f"Total: {report.total_queries}")
print(f"Parseable: {report.parseable_queries}")
print(f"Rewritable: {report.rewritable_queries}")
print(f"Coverage: {report.coverage_percentage:.1f}%")

# Missing components
for model in report.missing_models:
    print(f"Missing model: {model}")

for model, dims in report.missing_dimensions.items():
    for dim in dims:
        print(f"Missing dimension: {model}.{dim}")
```

### Per-Query Analysis

```python
for analysis in report.query_analyses:
    if not analysis.can_rewrite:
        print(f"Missing models: {analysis.missing_models}")
        print(f"Missing dimensions: {analysis.missing_dimensions}")
        print(f"Missing metrics: {analysis.missing_metrics}")
```

### With Database Connection

```python
import duckdb

conn = duckdb.connect(":memory:")
conn.execute("CREATE TABLE orders (id INT, customer_id INT, amount DECIMAL)")
conn.execute("CREATE TABLE customers (id INT, region VARCHAR)")

# Uses information_schema for better inference
analyzer = CoverageAnalyzer(layer, connection=conn)
```

Benefits:
- Resolves ambiguous columns
- Infers relationships from foreign keys
- Detects primary keys

## Migration Workflow

### 1. Generate Models

```bash
sidemantic coverage-analyzer analyze queries/ --output-dir models/generated/
```

### 2. Review and Refine

```python
models = analyzer.generate_models(report)

for name, model_def in models.items():
    print(f"{name}: {len(model_def.get('dimensions', []))} dims, {len(model_def.get('metrics', []))} metrics")
```

### 3. Merge Multiple Analyses

```python
report1 = analyzer.analyze_queries(queries_set1)
report2 = analyzer.analyze_queries(queries_set2)

all_analyses = report1.query_analyses + report2.query_analyses
combined_report = CoverageReport(
    total_queries=len(all_analyses),
    parseable_queries=sum(1 for a in all_analyses if not a.parse_error),
    rewritable_queries=sum(1 for a in all_analyses if a.can_rewrite),
    query_analyses=all_analyses
)

models = analyzer.generate_models(combined_report)
```

### 4. Test Rewrites

```python
rewritten = analyzer.generate_rewritten_queries(report)

for query_name, sql in rewritten.items():
    original_result = conn.execute(original_queries[query_name]).fetchdf()
    rewritten_result = conn.execute(sql).fetchdf()
    assert original_result.equals(rewritten_result)
```

### 5. Deploy

```bash
cp models/generated/*.yml models/
sidemantic load models/
```

## Troubleshooting

### Low Coverage

**Cause**: Missing models, dimensions, or metrics.

**Fix**:
```python
# Generate and load models
models = analyzer.generate_models(report)
analyzer.write_model_files(models, "models/")

layer = SemanticLayer.from_folder("models/")
analyzer = CoverageAnalyzer(layer)
report = analyzer.analyze_queries(queries)  # Higher coverage now
```

### Dimensions Not Extracted

**Cause**: No `GROUP BY` clause.

```sql
-- ❌ No dimensions (no GROUP BY)
SELECT COUNT(*) FROM orders

-- ✅ Extracts status
SELECT status, COUNT(*) FROM orders GROUP BY status
```

### Relationships Not Detected

**Causes**:
- Non-equi joins
- Complex conditions
- Multiple join keys

**Fix**: Provide database connection for FK detection or manually define relationships.

### Metric Names Don't Match

Analyzer generates names from `agg_column`:
- `SUM(amount)` → `sum_amount`
- `COUNT(*)` → `count`

Use aliases to control names:
```sql
SELECT SUM(amount) as total_revenue FROM orders  -- Generates "total_revenue"
```

## Best Practices

1. Start with simple queries for baseline coverage
2. Generate models to get 80% coverage quickly
3. Refine incrementally
4. Test old vs new queries in parallel
5. Migrate one dashboard at a time

### Maintain Coverage in CI

```python
def test_query_coverage():
    analyzer = CoverageAnalyzer(layer)
    report = analyzer.analyze_folder("queries/")

    assert report.coverage_percentage >= 90.0
    assert report.parseable_queries == report.total_queries
```
